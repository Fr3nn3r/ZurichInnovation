
+++++++++++++++++++++++++ Python Script for Folder Context Extraction V0
Write a python script that takes a folder (basefolder) as input parameter and produces a txt file 

List all files contained in basefolder at any level of the folder structure:
  - file_0
  - file_1  
  - ...
  - file_n


output-file-name: basefolder-context.txt
output-file-location: ouput folder
output-file-structure:
---
Context file: "file_0_relative_to_basefolder_pathname"
<content_of_file_0_in_plain_text>
---
Context file: "file_1_relative_to_basefolder_pathname"
<content_of_file_1_in_plain_text>
---
...
---
Context file: "file_n_relative_to_basefolder_pathname"
<content_of_file_n_in_plain_text>
---

for pdf files use Tesseract (example available in src/simple_ocr.py)
for txt, json, any markup language, include the text verbatim
for image formats use BOTH 
  - openai image to text API to get a clear description of the image (example available in src/image_to_text_analyzer.py)
  - AND Tesseract OCR
  Format the content as follow:
  AI description: <open_ai_image_to_text>
  OCR: <OCR_text>

You must log progress all the way throught and provide detailed logging.
The function must be callable from the CLI and from a programmatic interface.

++++++++++++++++++++++++++++++++++ GPT4.1 version: 1.0
+++++++++++++++++++++++++++++++++ Prompt: Python Script for Folder Context Extraction (JSON Output)
Write a Python script that:

Inputs:
basefolder (path to folder to process)
output_folder (optional, default: current working directory)

Behavior
Recursively scan basefolder for all files at any depth.
For each file, create a JSON entry with:
"relative_path": path relative to basefolder
"file_type": detected file type (e.g. pdf, image, text, json, etc.)
"content": see rules below

File handling rules:
Text, JSON, markup files:
Read content as plain text.

PDF files:
Extract text using Tesseract OCR (src/simple_ocr.py for example).

Image files (e.g., .png, .jpg):
Use OpenAI Image-to-Text API (see src/image_to_text_analyzer.py) to get "ai_description".
Use Tesseract OCR to get "ocr_text".
Store both under "content": { "ai_description": "...", "ocr_text": "..." }

Logging:
Log all major steps and per-file processing with the logging module (including progress)

Usability:
Script should be executable both as a CLI and as a Python function.

CLI arguments:
basefolder (positional)

--output_folder (optional)

Function interface:

def generate_context(basefolder: str, output_folder: Optional[str] = None) -> None:

Output:

JSON file named {basefolder_name}-context.json in output_folder

Top-level structure: a list of file context entries

[
  {
    "relative_path": "docs/report.pdf",
    "file_type": "pdf",
    "content": "<text extracted via Tesseract>"
  },
  {
    "relative_path": "images/logo.png",
    "file_type": "image",
    "content": {
      "ai_description": "<OpenAI description>",
      "ocr_text": "<Tesseract output>"
    }
  },
  {
    "relative_path": "data/config.json",
    "file_type": "json",
    "content": "{...file contents...}"
  }
  // etc.
]
Special notes:

Use error handling for unreadable files (log and skip).
Output file must be valid UTF-8 JSON
If you encounter an unsupported file display a warning message and continue

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Add support for excel and csv files, convert them to json:
  {
    "relative_path": "data/prices.xls",
    "file_type": "xls",
    "content": "{...file contents...}"
  }

++++++++++++++++++++++++++++++++++++++++++++++++ before commit "Working on inproving data quality"
For PDF files, we need to detect when Tesseract OCR processing has failed if the output is sparse, mostly empty, or gibberish (use simple rules: not enough alphanumeric chars relative to the filesize, weird symbol ratios, etc.) we want to fallback to OPenAI image to text. 

Here is a new prompt to use for the openAI vision API (all calls):

You are an AI assistant for universal document and image processing.
For the image provided:

If the image is a document (receipt, ticket, invoice, form, etc.), extract all visible information in structured JSON format (include key fields, tables, totals, dates, etc.).

If the image is a photo (e.g., a vehicle, damaged property, or objects), describe the content and any visible details as clearly as possible.

In all cases, identify the type of image or document, and include this as a field in your output.

Output JSON Example:
{
  "detected_type": "receipt",
  "fields": { "total": "874,000", ... },
  "raw_text": "full OCR text here",
  "image_description": "not applicable"
}
+++++++++++++++++++++++++++++++++++++++++++++
now for each new dataset context in output, insert a new row in n8n_context_cache, context_key=dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id=01- Claims- Travel- Canada, data_upload_id=zurich_07_2025 

+++++++++++++++++++++++++++++++++++++
ok now run generate_context.py for all the folder in "C:\Users\fbrun\Documents\GitHub\ZurichInnovation\data\01- Claims- Travel- Canada\Data\Sample Travel Claim Files" (in the output folder) and also update the analysis.xlsx file in the process

+++++++++++++++++++++++++++

for each context file in the output foder I want a estimate of the number od tokens in it and compute the overall size of the corresponding original folder in .\data\01- Claims- Travel- Canada\Data\Sample claims files 2\ in KB 
append a new row in an excel sheet for each context-file/dataset with basefoldername,folder_size_in_KB, estimated_tokens 

++++++++++++++++++++++++
now for each new dataset context in output, insert a new row in n8n_context_cache, context_key=base_filename without-context.json, dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id=01- Claims- Travel- Canada, data_upload_id=zurich_07_2025

++++++++++++++++++++++++++++++++++++++++++++++++++++++
create a python script using OpenAI whisper API of this video, I care only about the sound transcript, create a txt file in the same folder with a shorter name. Then use GPT4.0 to create a summary of the transcript with each Q&A, create a summary.txt in the same folder. C:\Users\fbrun\Documents\GitHub\ZurichInnovation\data\01- Claims- Travel- Canada\Ask Me Anything Session Recording\Ask Me Anything Session – Agentic AI HyperChallenge - Straight-through-processing for high-volume claims-20250624_153102-Meeting Recording.mp4
Later, if it works I will ask you to run the same script on many videos.

+++++++++++++++++++++++++++++++++++++++++++++++++++++
Add docx files support to the generate_context.py

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
There is not enough comments in our code, take all the files in src folder and add a comment section at the top describing what the file does at a high level. Do not change the code cimply add a comment section to each .py file so that I can undertsand what it does immediately when I click on the editor

++++++++++++++++++++++++++++++
ok now run generate_context.py for all the folder in "C:\Users\fbrun\Documents\GitHub\ZurichInnovation\data\02- Claims- Motor Liability- UK\Data\TEMP" (in the output folder) and also update the output\analysis.xlsx file in the process

++++++++++++++++++++++++++++++++++++++++
in the outpiut folder there is an excel file with these columns:
basefoldername,folder_size_in_KB,estimated_tokens, zurich_challenge_id

consider the original source folder: "ata\02- Claims- Motor Liability- UK\Data\TEMP"

for each context.json in the output folder add one row to the sheet:
basefoldername (from the corresponding original folder - context filename without -context.json) ,basefolder_size_in_KB for this context.json,estimated_tokens of the context.json, "02- Claims- Motor Liability- UK"


++++++++++++++++++++++++++++++++

from the output/context_report.xlsx I would like to plot the distribution of estimated_tokens

+++++++++++++++++++++++++++++++++++
now for each new dataset context.json in output, insert a new row in n8n_context_cache, context_key=base_filename, dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id="02- Claims- Motor Liability- UK", data_upload_id=zurich_07_2025_json_v0
you can use upload_new_contexts but you must rewrite the logic of point "4.  **Upsert Logic (Check-Then-Act)**" the expected behavior it to ALWAYS upsert a new row, upload_new_contexts SHOULD NEVER update an existing row. Update the script,align the comments, and upsert the records.

++++++
now I want you to generate context files using generate_context.py for all folders contained in these 2 folders:
- data\03- Claims- Disability- Ecuador\Data\First 11  sample files
- data\03- Claims- Disability- Ecuador\Data\Sample 2 to share
also update the output/context_report.xlsx with zurich_challenge_id="03- Claims- Disability- Ecuador"

+++++++++++++ 
now for each new dataset -context.json in ./output, insert a new row in n8n_context_cache, context_key=base_filename, dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id="03- Claims- Disability- Ecuador", data_upload_id=zurich_07_2025_json_v0 you can use upload_new_contexts.py
++++++++++++++++++++++

now generate context files using generate_context.py for all folders contained in these 2 folders:
- data\04- Claims- Motor- Ecuador\Data\Ecuador-Vehicle Theft Sample Claim Files (Original)
- data\04- Claims- Motor- Ecuador\Data\New Sample Claims Files
also update the output/context_report.xlsx (basefoldername,folder_size_in_KB,estimated_tokens, zurich_challenge_id) with zurich_challenge_id="04- Claims- Motor- Ecuador"
+++++++
now for each new dataset -context.json in ./output/contexts, insert a new row in n8n_context_cache, context_key=base_filename, dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id="04- Claims- Motor- Ecuador", data_upload_id=zurich_07_2025_json_v0 you can use upload_new_contexts.py

++++++++++++++
only make required changes to the code

generate_context.py needs to be able to read docx files content and add it the the context just like other filetypes.

For all PDF files in input that contain scans:
    doc = fitz.open(pdf_path)
    scanned_pages = 0
    for page in doc:
      page.get_text() → Extracts visible text.
      page.get_images(full=True) → Detects embedded images.
If a page has no text but has images, it's likely scanned.
Then you must run the fallback OpenAI Vision to descibe the image (so it is added to the context).

now generate context files using generate_context.py for all folders contained in: data\02- Claims- Motor Liability- UK\Data\Sample Claims File -Customer at Fault
+++++++++++++++++++++++
only make required changes to the code
add .doc support to generate_context.py and rerun folders 16 and 14

+++++++++++++
now generate context files using generate_context.py for all folders contained in these 2 folders (one context per sub-folder of these 2):
- data\05- Claims- Liability Decisions- Canada\Data\Canada - Liability decisions data files
- data\05- Claims- Liability Decisions- Canada\Data\Sample 2 to share

++++++
I want to create a mode for generate_context.py where we run every PDF page by OpenAI vision, no OCR, just OpenAI vision. 
and then using the new mode generate context files using generate_context.py for all folders contained in these 2 folders (one context per sub-folder of these 2):
- data\05- Claims- Liability Decisions- Canada\Data\Canada - Liability decisions data files
- data\05- Claims- Liability Decisions- Canada\Data\Sample 2 to share
+++
Using the new OpenAI vision mode to generate context files using generate_context.py for all folders contain in this folder:
data\04- Claims- Motor- Ecuador\Data\New Sample Claims Files


++++++++++

for each new dataset in ./output/Case Y-context.json, insert a new row in n8n_context_cache, context_key=base_filename, dataset_id=base_filename without-context.json, context_value=content of base_filname-context.json, zurich_challenge_id="05- Claims- Liability Decisions- Canada", data_upload_id=zurich_07_2025_json_v2 
you can use upload_new_contexts.py
IMPORTANT: YOU MUST INSERT ROWS DO NOT UPDATE OR DELETE ANY pre-existing data from the DB

++++++++

process only this session (using process_sessions_individual.py):
data\06- Underwriting- Mid Market-  Australia\Ask Me Anything Session Recording\Ask Me Anything Session – Agentic AI HyperChallenge - Transforming Mid-Market Property Insurance with a Digital Underwriting Solution-20250623_090307-Meeting Recording.mp4


++++++++++++++++++++++++
Write a script that lists all the eml files in C:\Users\fbrun\Documents\GitHub\ZurichInnovation\data\06- Underwriting- Mid Market-  Australia\Data\Additional Samples\BASEFILENAME.eml

and for each file creates folder BASEFILENAME containing what is in the archive (email + attachement) for example:

email.txt (full email data)
attachement1.pdf 
attachement2.xls
etc...

++++++++++

now generate context files using generate_context.py (OpenAI vision mode) for all folders contained in these 3 folders:

C:\Users\fbrun\Documents\GitHub\ZurichInnovation\input\eml_extractions\*
C:\Users\fbrun\Documents\GitHub\ZurichInnovation\input\New sample data to share- Double checked!\*
C:\Users\fbrun\Documents\GitHub\ZurichInnovation\input\Test data- original format\*

Outputfolder: C:\Users\fbrun\Documents\GitHub\ZurichInnovation\output\contexts\06


+++++++++++++++++++

in the output folder, create a sheet with one row per record from the table n8n_context_cache in supabase. The sheet must contain all columns except context_value, instead of context_value the sheet must contain a context_value_tokens column with the number of tokens estimated from the content of the context_value column.

anaylze_output.py contains an example of how to count the tokens.



------- FB: backup 14.07.2025
now for all folder Sample 2 Claims.... / (Fault or Split Liability)/* create a context file in the output folder with all the text from the non-image non-video files (.md .html .json) include in the  context the description of the picture we created at the previous step (for all pictures we already have the description in the damage-analysis file)

now for each new dataset context, insert a new row in n8n_context_cache, context_key=dataset_id=base_filename without-context.txt, context_value=content of base_filname-context.txt, zurich_challenge_id=02- Claims- Motor Liability- UK, data_upload_id=zurich_07_2025 

for all folder in "Data - New UW Sample" create a txt context file (filename=foldername) in the output folder containing all the text from all the files included in the folder. The content of the context files should look like:
Filename: XXXXX.txt
<content of XXXXX.txt>
----
Filename: ABS.pdf
<content of ABS.pdf>
----
etc...
for PDF files use the code in @simple_ocr.py to extract the text
for excel files convert content into CSV format
Any doubt ask questions,